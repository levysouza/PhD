{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lss9/anaconda3/envs/matchzoo/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Using TensorFlow backend.\n",
      "/home/lss9/anaconda3/envs/matchzoo/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import matchzoo as mz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../../train_data/train_data_1_1', delimiter=',')\n",
    "validation_dataset = pd.read_csv('../../train_data/validation_data_1_1', delimiter=',')\n",
    "\n",
    "train_dataset = train_dataset.replace(np.nan, ' ', regex=True)\n",
    "validation_dataset = validation_dataset.replace(np.nan, ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.head(1000)\n",
    "validation_dataset = validation_dataset.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data1 = []\n",
    "for i, row in train_dataset.iterrows():\n",
    "    \n",
    "    line1 = {'id_left': str(row['article_id']),\n",
    "            'text_left':str(row['article_page_title']),\n",
    "            'id_right':str(row['table_id']),\n",
    "            'text_right':str(row['table_page_title']),\n",
    "            'label':row['label']\n",
    "           }\n",
    "    \n",
    "    list_data1.append(line1)\n",
    "\n",
    "df1 = pd.DataFrame(list_data1)\n",
    "train_pack = mz.pack(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data2 = []\n",
    "for i, row in validation_dataset.iterrows():\n",
    "    \n",
    "    line2 = {'id_left': str(row['article_id']),\n",
    "            'text_left':str(row['article_page_title']),\n",
    "            'id_right':str(row['table_id']),\n",
    "            'text_right':str(row['table_page_title']),\n",
    "            'label':row['label']\n",
    "           }\n",
    "    \n",
    "    list_data2.append(line2)\n",
    "\n",
    "df2 = pd.DataFrame(list_data2)\n",
    "valid_pack = mz.pack(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_task = mz.tasks.Ranking(loss=mz.losses.RankHingeLoss())\n",
    "ranking_task.metrics = [\n",
    "    mz.metrics.MeanAveragePrecision()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = mz.datasets.embeddings.load_glove_embedding(dimension=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval => NgramLetter: 100%|██████████| 989/989 [00:00<00:00, 6564.89it/s]\n",
      "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval => NgramLetter: 100%|██████████| 996/996 [00:00<00:00, 8657.87it/s]\n",
      "Processing text_left with extend: 100%|██████████| 989/989 [00:00<00:00, 415898.00it/s]\n",
      "Processing text_right with extend: 100%|██████████| 996/996 [00:00<00:00, 501564.03it/s]\n",
      "Building Vocabulary from a datapack.: 100%|██████████| 53383/53383 [00:00<00:00, 2929652.22it/s]\n",
      "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 989/989 [00:00<00:00, 7782.03it/s]\n",
      "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 996/996 [00:00<00:00, 10127.44it/s]\n",
      "Processing text_left with transform: 100%|██████████| 989/989 [00:00<00:00, 103275.57it/s]\n",
      "Processing text_right with transform: 100%|██████████| 996/996 [00:00<00:00, 109473.97it/s]\n",
      "Processing text_left with chain_transform of NgramLetter => WordHashing: 100%|██████████| 989/989 [00:01<00:00, 524.66it/s]\n",
      "Processing text_right with chain_transform of NgramLetter => WordHashing: 100%|██████████| 996/996 [00:01<00:00, 532.98it/s]\n",
      "Processing text_left with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 988/988 [00:00<00:00, 6345.07it/s]\n",
      "Processing text_right with chain_transform of Tokenize => Lowercase => PuncRemoval => StopRemoval: 100%|██████████| 992/992 [00:00<00:00, 9698.65it/s]\n",
      "Processing text_left with transform: 100%|██████████| 988/988 [00:00<00:00, 100481.86it/s]\n",
      "Processing text_right with transform: 100%|██████████| 992/992 [00:00<00:00, 115730.68it/s]\n",
      "Processing text_left with chain_transform of NgramLetter => WordHashing: 100%|██████████| 988/988 [00:01<00:00, 582.82it/s]\n",
      "Processing text_right with chain_transform of NgramLetter => WordHashing: 100%|██████████| 992/992 [00:02<00:00, 448.30it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = mz.preprocessors.CDSSMPreprocessor(fixed_length_left=10, fixed_length_right=10)\n",
    "train_pack_processed = preprocessor.fit_transform(train_pack)\n",
    "valid_pack_processed = preprocessor.transform(valid_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_left (InputLayer)          (None, 10, 4166)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_right (InputLayer)         (None, 10, 4166)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 10, 64)       799936      text_left[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 10, 64)       799936      text_right[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 64)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           4160        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_2[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,616,514\n",
      "Trainable params: 1,616,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mz.models.CDSSM()\n",
    "model.params['input_shapes'] = preprocessor.context['input_shapes']\n",
    "model.params['task'] = ranking_task\n",
    "model.params['filters'] = 64\n",
    "model.params['kernel_size'] = 3\n",
    "model.params['strides'] = 1\n",
    "model.params['padding'] = 'same'\n",
    "model.params['conv_activation_func'] = 'tanh'\n",
    "model.params['w_initializer'] = 'glorot_normal'\n",
    "model.params['b_initializer'] = 'zeros'\n",
    "model.params['mlp_num_layers'] = 1\n",
    "model.params['mlp_num_units'] = 64\n",
    "model.params['mlp_num_fan_out'] = 64\n",
    "model.params['mlp_activation_func'] = 'tanh'\n",
    "model.params['dropout_rate'] = 0.8\n",
    "model.params['optimizer'] = 'adadelta'\n",
    "model.guess_and_fill_missing_params()\n",
    "model.build()\n",
    "model.compile()\n",
    "model.backend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = mz.DataGenerator(\n",
    "    train_pack_processed,\n",
    "    mode='pair',\n",
    "    num_dup=2,\n",
    "    num_neg=1,\n",
    "    batch_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x, pred_y = valid_pack_processed[:].unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = mz.callbacks.EvaluateAllMetrics(model, x=pred_x, y=pred_y, batch_size=len(pred_x), model_save_path='CDSSM_title', once_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 1.0279\n",
      "Validation: mean_average_precision(0.0): 0.5096153846153846\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9779\n",
      "Validation: mean_average_precision(0.0): 0.5096153846153846\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9356\n",
      "Validation: mean_average_precision(0.0): 0.5101214574898786\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9746\n",
      "Validation: mean_average_precision(0.0): 0.5101214574898786\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9065\n",
      "Validation: mean_average_precision(0.0): 0.5106275303643725\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=5, callbacks=[evaluate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
