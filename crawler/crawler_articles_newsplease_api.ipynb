{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) \n",
    "from newsplease import NewsPlease\n",
    "import logging\n",
    "import threading\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(example_sent):\n",
    "    \n",
    "    word_tokens = word_tokenize(example_sent) \n",
    "  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    formattedText = \"\"\n",
    "\n",
    "    for word in filtered_sentence:\n",
    "        \n",
    "        if (len(word)>2):\n",
    "            \n",
    "            formattedText = formattedText + \" \" +word\n",
    "    \n",
    "    \n",
    "    formattedText = formattedText.lstrip()\n",
    "    \n",
    "    formattedText = formattedText.rstrip()\n",
    "        \n",
    "    return formattedText.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_string(text):\n",
    "    \n",
    "    text = re.sub('[^A-Za-z]+',' ',text)\n",
    "    \n",
    "    text = text.lstrip()\n",
    "    \n",
    "    text = text.rstrip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_articles = pd.read_csv('../dataset/articlesLinks', delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_articles = data_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_articles = []\n",
    "\n",
    "for i, row in tqdm(data_articles.iterrows()):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        crawler = NewsPlease.from_url(row[1])\n",
    "\n",
    "        article_title = remove_stopwords(clear_string(str(crawler.title)))\n",
    "        article_description = remove_stopwords(clear_string(str(crawler.description)))\n",
    "        article_main_text = remove_stopwords(clear_string(str(crawler.maintext)))\n",
    "\n",
    "        line = {'article_id': row[0],\n",
    "                'article_title': article_title,\n",
    "                'article_description':article_description,\n",
    "                'article_main_text':article_main_text}\n",
    "        \n",
    "        list_articles.append(line)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(list_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('articles_news_please_crawler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_webpage_data(article_id, article_url):\n",
    "          \n",
    "#     crawler = NewsPlease.from_url(article_url, timeout=6)\n",
    "\n",
    "#     article_title = str(crawler.title)\n",
    "#     article_description = str(crawler.description)\n",
    "#     article_main_text = str(crawler.maintext)\n",
    "\n",
    "#     line = {'article_id': article_id,\n",
    "#             'article_title': article_title,\n",
    "#             'article_description':article_description,\n",
    "#             'article_main_text':article_main_text}\n",
    "\n",
    "#     return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawler_result = []\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    \n",
    "#     futures = []\n",
    "    \n",
    "#     for i, row in tqdm(data_articles.iterrows()):\n",
    "        \n",
    "#         try:\n",
    "        \n",
    "#             futures.append(executor.submit(get_webpage_data, article_id = row[0], article_url=row[1]))\n",
    "        \n",
    "#         except:\n",
    "            \n",
    "#             continue\n",
    "            \n",
    "#     for future in concurrent.futures.as_completed(futures):\n",
    "       \n",
    "#         try:\n",
    "            \n",
    "#             crawler_result.append(future.result())\n",
    "            \n",
    "#         except:\n",
    "            \n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
