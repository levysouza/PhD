{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim as gs\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "indexing_tables = Elasticsearch(timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles = pd.read_csv('dataset/test_articles_dataset_newyork.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = gs.models.FastText.load('../train_embedding_models/fasttext_embedding_50d_all_signals')\n",
    "# embedding_model = gs.models.FastText.load('train_embedding_model/fasttext_embedding_50d_all_signals_newyorkdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_tables.indices.close(index='data_table_newyork')\n",
    "indexing_tables.indices.put_settings(index='data_table_newyork', body={\"index\": {\"similarity\": {\"default\": {\"type\": \"BM25\"}}}})\n",
    "indexing_tables.indices.open(index='data_table_newyork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_indexing(query):\n",
    "    \n",
    "    result= indexing_tables.search(\n",
    "        index=\"data_table_newyork\", \n",
    "        body = {\n",
    "        \"_source\": [\"table_url\",\"table_page_title\",\"table_page_content\",\"table_page_keywords\"],\n",
    "        \"from\" : 0,\n",
    "        \"size\" : 100,\n",
    "        \"query\": {\n",
    "            \"multi_match\":{\n",
    "              \"type\": \"most_fields\",\n",
    "              \"query\":    query, \n",
    "              \"fields\": [\"table_page_title\",\"table_page_content\",\"table_page_keywords\"] \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ID_goal,ranked_tables_ID):\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for table_ID in ranked_tables_ID:\n",
    "        \n",
    "        if table_ID == ID_goal:\n",
    "    \n",
    "            accuracy = 1\n",
    "            break;\n",
    "            \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAD = 55\n",
    "\n",
    "def sequence_padding(X_DIM, value):\n",
    "    \n",
    "    value_padding = np.pad(value, ((0,MAX_PAD - X_DIM),(0,0)), 'constant')\n",
    "    \n",
    "    return value_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(value):\n",
    "\n",
    "    value = tknzr.tokenize(str(value))\n",
    "    \n",
    "    if len(value) < MAX_PAD:\n",
    "        \n",
    "        embedding = embedding_model.wv[value]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        padding_embedding = sequence_padding(embedding.shape[0],embedding)\n",
    "        \n",
    "        return padding_embedding\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        embedding = embedding_model.wv[value[0:MAX_PAD]]\n",
    "        embedding = embedding.astype('float16')\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(article_title):\n",
    "    \n",
    "    tables_index = []\n",
    "\n",
    "    result_index = search_indexing(article_title)\n",
    "        \n",
    "    for hit in result_index['hits']['hits']:\n",
    "    \n",
    "        table_ID = hit['_source']['table_url']\n",
    "        \n",
    "        table_page_title = hit['_source']['table_page_title']\n",
    "        \n",
    "        table_page_cotent = hit['_source']['table_page_content'][0:1000]\n",
    "        \n",
    "        table_page_keywords = hit['_source']['table_page_keywords']\n",
    "    \n",
    "        tables_index.append([table_ID,table_page_title,table_page_cotent,table_page_keywords])\n",
    "    \n",
    "    return tables_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affinity_model_title_main_passage_keywords_1_1_34_0.9841.h5 \n",
    "# attention_model_title_main_passage_keywords_1_1_23_0.9844.h51\n",
    "# coattention_model_title_main_passage_keywords_1_1_11_0.9621.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model = tf.keras.models.load_model('../model_title_main_passage_keywords/coattention_model_title_main_passage_keywords_1_1_39_0.9740.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def run_search(k):\n",
    "    \n",
    "    TOP_K = k\n",
    "    accuracy = []\n",
    "    \n",
    "    for i,row in tqdm(raw_articles.iterrows()):\n",
    "    \n",
    "        article_title = []\n",
    "        article_main_passage = []\n",
    "        article_keywords = []\n",
    "        \n",
    "        title_table = []\n",
    "        table_page_content = []\n",
    "        table_keywords = []\n",
    "        \n",
    "        ranked_tables_model = []\n",
    "    \n",
    "        article_ID = row['article_key_match']\n",
    "        article_title_text = str(row['article_title'])\n",
    "        article_main_passage_text = str(row['article_main_passage'][0:1000])\n",
    "        article_meta_description_text = str(row['article_meta_description'])\n",
    "        article_keywords_text = str(row['article_title'])\n",
    "        \n",
    "        catch = article_title_text+\" \"+article_main_passage_text+\" \"+article_keywords_text\n",
    "        \n",
    "        ranked_tables_index = search_index(catch)\n",
    "        \n",
    "        article_title_embedding = create_embedding(article_title_text)\n",
    "        article_main_passage_embedding = create_embedding(article_main_passage_text)\n",
    "        article_keywords_embedding = create_embedding(article_keywords_text)\n",
    "        \n",
    "        for table_ID, table_title_index, table_page_content_index, table_keywords_index in (ranked_tables_index):\n",
    "            \n",
    "            table_title_embedding = create_embedding(str(table_title_index))\n",
    "            table_page_content_embedding = create_embedding(str(table_page_content_index))\n",
    "            table_page_keywords_embedding = create_embedding(str(table_keywords_index))\n",
    "            \n",
    "            article_title.append(article_title_embedding)\n",
    "            article_main_passage.append(article_main_passage_embedding)\n",
    "            article_keywords.append(article_keywords_embedding)\n",
    "            \n",
    "            title_table.append(table_title_embedding)\n",
    "            table_page_content.append(table_page_content_embedding)\n",
    "            table_keywords.append(table_page_keywords_embedding)\n",
    "    \n",
    "        article_title = np.array(article_title)\n",
    "        article_main_passage = np.array(article_main_passage)\n",
    "        article_keywords = np.array(article_keywords)\n",
    "        \n",
    "        title_table = np.array(title_table)\n",
    "        table_page_content = np.array(table_page_content)\n",
    "        table_keywords = np.array(table_keywords)\n",
    "    \n",
    "        table_ranking_model = ranking_model.predict([article_title,article_main_passage,article_keywords,title_table,table_page_content,table_keywords])\n",
    "    \n",
    "        for i in range(0,len(table_ranking_model)):\n",
    "        \n",
    "            ranked_tables_model.append([ranked_tables_index[i][0],ranked_tables_index[i][1],table_ranking_model[i][0]]) \n",
    "        \n",
    "        data_frame = pd.DataFrame(ranked_tables_model, columns = ['table_ID', 'table_title','table_ranking']) \n",
    "        data_frame_sorting = data_frame.sort_values('table_ranking', ascending=False)\n",
    "        final_ranked_tables = data_frame_sorting.iloc[0:TOP_K,0:1].values\n",
    "        \n",
    "#         selected_top = data_frame_sorting.head(TOP_K)\n",
    "#         min_score = selected_top['table_ranking'].min()\n",
    "#         draw_tables_socres = data_frame_sorting[data_frame_sorting['table_ranking'] >= min_score]\n",
    "#         final_ranked_tables = draw_tables_socres.iloc[:,0:1].values\n",
    "           \n",
    "        accuracy.append(get_accuracy(article_ID, final_ranked_tables))\n",
    "        \n",
    "    result.append([\"Acc@\"+str(k),str(round(np.mean(accuracy),4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_K = [1,5,10,20]\n",
    "\n",
    "for k in accuracy_K:\n",
    "     \n",
    "    run_search(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
