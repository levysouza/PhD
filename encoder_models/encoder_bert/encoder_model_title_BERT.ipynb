{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer, TFBertMainLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU not found')\n",
    "print('found GPU at {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertModel.from_pretrained(\"bert-base-cased\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert_layer = TFBertMainLayer(bert_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../train_data/train_triple_all_signals.csv', delimiter=',')\n",
    "validation_data = pd.read_csv('../train_data/validation_triple_all_signals.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.head(100)\n",
    "# validation_data = validation_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_dummy = np.empty(len(train_data))\n",
    "Y_validation_dummy = np.empty(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_article_title = []\n",
    "input_masks_article_title = []\n",
    "input_token_id_article_title = []\n",
    "\n",
    "input_ids_table_true_title = []\n",
    "input_masks_table_true_title = []\n",
    "input_token_id_table_true_title = []\n",
    "\n",
    "input_ids_table_false_title = []\n",
    "input_masks_table_false_title = []\n",
    "input_token_id_table_false_title = []\n",
    "\n",
    "for i,row in tqdm(train_data.iterrows()):\n",
    "    \n",
    "    article_page_title = str(row['article_page_title'])\n",
    "    true_table_page_title = str(row['true_table_page_title'])\n",
    "    false_table_page_title = str(row['false_table_page_title'])\n",
    "    \n",
    "    article_page_description = str(row['article_page_meta_description'])\n",
    "    true_table_page_description = str(row['true_table_page_summary'])\n",
    "    false_table_page_description = str(row['false_table_page_summary'])\n",
    "    \n",
    "    #encoder article title\n",
    "    return_tokenizer1 = bert_tokenizer.encode_plus(\n",
    "      article_page_title,\n",
    "      article_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    input_ids_article_title.append(return_tokenizer1['input_ids'])\n",
    "    input_masks_article_title.append(return_tokenizer1['attention_mask'])\n",
    "    input_token_id_article_title.append(return_tokenizer1['token_type_ids'])  \n",
    "    \n",
    "    \n",
    "    #encoder table true title\n",
    "    return_tokenizer2 = bert_tokenizer.encode_plus(\n",
    "      true_table_page_title,\n",
    "      true_table_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    input_ids_table_true_title.append(return_tokenizer2['input_ids'])\n",
    "    input_masks_table_true_title.append(return_tokenizer2['attention_mask'])\n",
    "    input_token_id_table_true_title.append(return_tokenizer2['token_type_ids'])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #encoder table true false\n",
    "    return_tokenizer3 = bert_tokenizer.encode_plus(\n",
    "      false_table_page_title,\n",
    "      false_table_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    input_ids_table_false_title.append(return_tokenizer3['input_ids'])\n",
    "    input_masks_table_false_title.append(return_tokenizer3['attention_mask'])\n",
    "    input_token_id_table_false_title.append(return_tokenizer3['token_type_ids'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_article_title = np.asarray(input_ids_article_title, dtype='int32')\n",
    "input_masks_article_title = np.asarray(input_masks_article_title, dtype='int32')\n",
    "input_token_id_article_title = np.asarray(input_token_id_article_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_table_true_title = np.asarray(input_ids_table_true_title, dtype='int32')\n",
    "input_masks_table_true_title = np.asarray(input_masks_table_true_title, dtype='int32')\n",
    "input_token_id_table_true_title = np.asarray(input_token_id_table_true_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_table_false_title = np.asarray(input_ids_table_false_title, dtype='int32')\n",
    "input_masks_table_false_title = np.asarray(input_masks_table_false_title, dtype='int32')\n",
    "input_token_id_table_false_title = np.asarray(input_token_id_table_false_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids_article_title = []\n",
    "val_input_masks_article_title = []\n",
    "val_input_token_id_article_title = []\n",
    "\n",
    "val_input_ids_table_true_title = []\n",
    "val_input_masks_table_true_title = []\n",
    "val_input_token_id_table_true_title = []\n",
    "\n",
    "val_input_ids_table_false_title = []\n",
    "val_input_masks_table_false_title = []\n",
    "val_input_token_id_table_false_title = []\n",
    "\n",
    "for i,row in tqdm(validation_data.iterrows()):\n",
    "    \n",
    "    article_page_title = str(row['article_page_title'])\n",
    "    true_table_page_title = str(row['true_table_page_title'])\n",
    "    false_table_page_title = str(row['false_table_page_title'])\n",
    "    \n",
    "    article_page_description = str(row['article_page_meta_description'])\n",
    "    true_table_page_description = str(row['true_table_page_summary'])\n",
    "    false_table_page_description = str(row['false_table_page_summary'])\n",
    "    \n",
    "    #encoder article title\n",
    "    return_tokenizer1 = bert_tokenizer.encode_plus(\n",
    "      article_page_title,\n",
    "      article_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    val_input_ids_article_title.append(return_tokenizer1['input_ids'])\n",
    "    val_input_masks_article_title.append(return_tokenizer1['attention_mask'])\n",
    "    val_input_token_id_article_title.append(return_tokenizer1['token_type_ids'])  \n",
    "    \n",
    "    \n",
    "    #encoder table true title\n",
    "    return_tokenizer2 = bert_tokenizer.encode_plus(\n",
    "      true_table_page_title,\n",
    "      true_table_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    val_input_ids_table_true_title.append(return_tokenizer2['input_ids'])\n",
    "    val_input_masks_table_true_title.append(return_tokenizer2['attention_mask'])\n",
    "    val_input_token_id_table_true_title.append(return_tokenizer2['token_type_ids'])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #encoder table true false\n",
    "    return_tokenizer3 = bert_tokenizer.encode_plus(\n",
    "      false_table_page_title,\n",
    "      false_table_page_description,\n",
    "      max_length=MAX_TOKENS,\n",
    "      add_special_tokens=True,\n",
    "      return_token_type_ids=True,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      #return_tensors='tf',\n",
    "    )\n",
    "    \n",
    "    val_input_ids_table_false_title.append(return_tokenizer3['input_ids'])\n",
    "    val_input_masks_table_false_title.append(return_tokenizer3['attention_mask'])\n",
    "    val_input_token_id_table_false_title.append(return_tokenizer3['token_type_ids'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids_article_title = np.asarray(val_input_ids_article_title, dtype='int32')\n",
    "val_input_masks_article_title = np.asarray(val_input_masks_article_title, dtype='int32')\n",
    "val_input_token_id_article_title = np.asarray(val_input_token_id_article_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids_table_true_title = np.asarray(val_input_ids_table_true_title, dtype='int32')\n",
    "val_input_masks_table_true_title = np.asarray(val_input_masks_table_true_title, dtype='int32')\n",
    "val_input_token_id_table_true_title = np.asarray(val_input_token_id_table_true_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids_table_false_title = np.asarray(val_input_ids_table_false_title, dtype='int32')\n",
    "val_input_masks_table_false_title = np.asarray(val_input_masks_table_false_title, dtype='int32')\n",
    "val_input_token_id_table_false_title = np.asarray(val_input_token_id_table_false_title, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.5):\n",
    "     \n",
    "    anchor = y_pred[:,0:768]\n",
    "    positive = y_pred[:,768:1536]\n",
    "    negative = y_pred[:,1536:2304]\n",
    "        \n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = tf.keras.layers.Dot(axes=1,normalize=True)([anchor, positive])\n",
    "    \n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = tf.keras.layers.Dot(axes=1,normalize=True)([anchor, negative])\n",
    "    \n",
    "    # compute loss\n",
    "    basic_loss = (1 - pos_dist) - (1 - neg_dist) + alpha\n",
    "    loss = tf.keras.backend.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_title_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='input_token1', dtype='int32')\n",
    "article_title_mask_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='masked_token1', dtype='int32')\n",
    "article_title_token_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='token_ids_token1', dtype='int32')\n",
    "\n",
    "table_true_title_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='input_token2', dtype='int32')\n",
    "table_true_title_mask_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='masked_token2', dtype='int32')\n",
    "table_true_title_token_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='token_ids_token2', dtype='int32')\n",
    "\n",
    "table_false_title_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='input_token3', dtype='int32')\n",
    "table_false_title_mask_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='masked_token3', dtype='int32')\n",
    "table_false_title_token_id = tf.keras.layers.Input(shape=(MAX_TOKENS,), name='token_ids_token3', dtype='int32')\n",
    "\n",
    "#bert model layers\n",
    "last_hidden_state1, pooled_output1 = model_bert_layer([article_title_id,article_title_mask_id,article_title_token_id])\n",
    "last_hidden_state2, pooled_output2 = model_bert_layer([table_true_title_id,table_true_title_mask_id,table_true_title_token_id])\n",
    "last_hidden_state3, pooled_output3 = model_bert_layer([table_false_title_id,table_false_title_mask_id,table_false_title_token_id])\n",
    "\n",
    "concatenated = tf.keras.layers.Concatenate(axis=-1)([pooled_output1, pooled_output2, pooled_output3])\n",
    "\n",
    "model = tf.keras.Model(inputs=[article_title_id, \n",
    "                               article_title_mask_id,\n",
    "                               article_title_token_id,\n",
    "                               table_true_title_id,\n",
    "                               table_true_title_mask_id,\n",
    "                               table_true_title_token_id,\n",
    "                               table_false_title_id,\n",
    "                               table_false_title_mask_id,\n",
    "                               table_false_title_token_id], \n",
    "                       outputs = concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=triplet_loss,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"encoder_BERT_{epoch:02d}_{val_loss:.4f}.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([input_ids_article_title,\n",
    "                     input_masks_article_title,\n",
    "                     input_token_id_article_title,\n",
    "                     input_ids_table_true_title,\n",
    "                     input_masks_table_true_title,\n",
    "                     input_token_id_table_true_title,\n",
    "                     input_ids_table_false_title,\n",
    "                     input_masks_table_false_title,\n",
    "                     input_token_id_table_false_title], \n",
    "                    Y_train_dummy, \n",
    "                    epochs=5, \n",
    "                    batch_size=16,\n",
    "                    verbose=1,\n",
    "                    validation_data=([\n",
    "                     val_input_ids_article_title,\n",
    "                     val_input_masks_article_title,\n",
    "                     val_input_token_id_article_title,\n",
    "                     val_input_ids_table_true_title,\n",
    "                     val_input_masks_table_true_title,\n",
    "                     val_input_token_id_table_true_title,\n",
    "                     val_input_ids_table_false_title,\n",
    "                     val_input_masks_table_false_title,\n",
    "                     val_input_token_id_table_false_title], Y_validation_dummy),\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model.save_pretrained('fine_tuning_bert/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"encoder_bert.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
