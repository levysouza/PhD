{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles = pd.read_csv('../dataset/data_articles_train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of articles = 204107\n"
     ]
    }
   ],
   "source": [
    "print(\"total of articles = \"+str(len(raw_articles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204107 entries, 0 to 204106\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   full_text         204107 non-null  object\n",
      " 1   keywords          204107 non-null  object\n",
      " 2   meta_description  204107 non-null  object\n",
      " 3   meta_keywords     139997 non-null  object\n",
      " 4   page_id           204107 non-null  int64 \n",
      " 5   page_title        204107 non-null  object\n",
      " 6   summary           204107 non-null  object\n",
      " 7   tags              46867 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_articles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_lenght = []\n",
    "full_text_lenght = []\n",
    "meta_description_lenght = []\n",
    "summary_lenght = []\n",
    "keywords_lenght = []\n",
    "meta_keywords_lenght = []\n",
    "tags_lenght = []\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "for i,row in tqdm(raw_articles.iterrows()):\n",
    "    \n",
    "    title = str(row['page_title'])\n",
    "    full_text = str(row['full_text'])\n",
    "    meta_description = str(row['meta_description'])\n",
    "    summary = str(row['summary'])\n",
    "    keywords = str(row['keywords'])\n",
    "    meta_keywords = str(row['meta_keywords'])\n",
    "    tags = str(row['tags'])\n",
    "    \n",
    "    lenght_title = len(tknzr.tokenize(title))\n",
    "    lenght_full_text = len(tknzr.tokenize(full_text))\n",
    "    lenght_meta_description = len(tknzr.tokenize(meta_description))\n",
    "    lenght_summary = len(tknzr.tokenize(summary))\n",
    "    lenght_keywords = len(tknzr.tokenize(keywords))\n",
    "    lenght_meta_keywords = len(tknzr.tokenize(meta_keywords))\n",
    "    lenght_tags = len(tknzr.tokenize(tags))\n",
    "    \n",
    "    title_lenght.append(lenght_title)\n",
    "    full_text_lenght.append(lenght_full_text)\n",
    "    meta_description_lenght.append(lenght_meta_description)\n",
    "    summary_lenght.append(lenght_summary)\n",
    "    keywords_lenght.append(lenght_keywords)\n",
    "    meta_keywords_lenght.append(lenght_meta_keywords)\n",
    "    tags_lenght.append(lenght_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Title Analysis\n",
    "\n",
    "In the next code blocks we analyze the number of words in the article title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('title analysis:')\n",
    "print(\"max words = \"+str(np.max(title_lenght)))\n",
    "print(\"min words = \"+str(np.min(title_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(title_lenght)))\n",
    "print(\"std words = \"+str(np.std(title_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(title_lenght, range(0,35))\n",
    "plt.title('total of words in articles title')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.savefig('article_title1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Text Analysis\n",
    "\n",
    "In the next code blocks we analyze the number of words in the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('text analysis:')\n",
    "print(\"max words = \"+str(np.max(lenght_full_text)))\n",
    "print(\"min words = \"+str(np.min(lenght_full_text)))\n",
    "print(\"avg words = \"+str(np.mean(lenght_full_text)))\n",
    "print(\"std words = \"+str(np.std(lenght_full_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_text_lenght, range(0,300))\n",
    "plt.title('total of words in articles full text')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Meta Description Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('meta description analysis:')\n",
    "print(\"max words = \"+str(np.max(meta_description_lenght)))\n",
    "print(\"min words = \"+str(np.min(meta_description_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(meta_description_lenght)))\n",
    "print(\"std words = \"+str(np.std(meta_description_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(meta_description_lenght, range(0,2213))\n",
    "plt.title('total of words in articles meta description')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('summary analysis:')\n",
    "print(\"max words = \"+str(np.max(summary_lenght)))\n",
    "print(\"min words = \"+str(np.min(summary_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(summary_lenght)))\n",
    "print(\"std words = \"+str(np.std(summary_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(summary_lenght, range(0,750))\n",
    "plt.title('total of words in articles summary')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Keywords Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('keywords analysis:')\n",
    "print(\"max words = \"+str(np.max(keywords_lenght)))\n",
    "print(\"min words = \"+str(np.min(keywords_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(keywords_lenght)))\n",
    "print(\"std words = \"+str(np.std(keywords_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(keywords_lenght, range(0,35))\n",
    "plt.title('total of words in articles keywords')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Meta Keywords Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('meta keywords analysis:')\n",
    "print(\"max words = \"+str(np.max(meta_keywords_lenght)))\n",
    "print(\"min words = \"+str(np.min(meta_keywords_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(meta_keywords_lenght)))\n",
    "print(\"std words = \"+str(np.std(meta_keywords_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(meta_keywords_lenght, range(0,35))\n",
    "plt.title('total of words in articles meta keywords')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Tags Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('meta tags analysis:')\n",
    "print(\"max words = \"+str(np.max(tags_lenght)))\n",
    "print(\"min words = \"+str(np.min(tags_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(tags_lenght)))\n",
    "print(\"std words = \"+str(np.std(tags_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tags_lenght, range(0,1680))\n",
    "plt.title('total of words in articles tags')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = pd.read_csv('../dataset/data_articles_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_title_lenght = []\n",
    "TEST_meta_description_lenght = []\n",
    "TEST_keywords_lenght = []\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "for i,row in tqdm(test_articles.iterrows()):\n",
    "    \n",
    "    title = row['page_title']\n",
    "    meta_description = row['meta_description']\n",
    "    keywords = row['keywords']\n",
    "    \n",
    "    lenght_title = len(tknzr.tokenize(title))\n",
    "    lenght_meta_description = len(tknzr.tokenize(meta_description))\n",
    "    lenght_keywords = len(tknzr.tokenize(keywords))\n",
    "    \n",
    "    TEST_title_lenght.append(lenght_title)\n",
    "    TEST_meta_description_lenght.append(lenght_meta_description)\n",
    "    TEST_keywords_lenght.append(lenght_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('title analysis:')\n",
    "print(\"max words = \"+str(np.max(TEST_title_lenght)))\n",
    "print(\"min words = \"+str(np.min(TEST_title_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(TEST_title_lenght)))\n",
    "print(\"std words = \"+str(np.std(TEST_title_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TEST_title_lenght, range(0,25))\n",
    "plt.title('total of words in articles title')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.savefig('article_title1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('meta description analysis:')\n",
    "print(\"max words = \"+str(np.max(TEST_meta_description_lenght)))\n",
    "print(\"min words = \"+str(np.min(TEST_meta_description_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(TEST_meta_description_lenght)))\n",
    "print(\"std words = \"+str(np.std(TEST_meta_description_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TEST_meta_description_lenght, range(0,772))\n",
    "plt.title('total of words in articles meta description')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('keywords analysis:')\n",
    "print(\"max words = \"+str(np.max(TEST_keywords_lenght)))\n",
    "print(\"min words = \"+str(np.min(TEST_keywords_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(TEST_keywords_lenght)))\n",
    "print(\"std words = \"+str(np.std(TEST_keywords_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TEST_keywords_lenght, range(0,25))\n",
    "plt.title('total of words in articles keywords')\n",
    "plt.xlabel('total of words')\n",
    "plt.ylabel('total of articles (log)')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokens analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204107it [05:32, 614.60it/s]\n"
     ]
    }
   ],
   "source": [
    "title_lenght = []\n",
    "meta_description_lenght = []\n",
    "keywords_lenght = []\n",
    "\n",
    "for i,row in tqdm(raw_articles.iterrows()):\n",
    "    \n",
    "    title = str(row['page_title'])\n",
    "    meta_description = str(row['meta_description'])\n",
    "    keywords = str(row['keywords'])\n",
    "    \n",
    "    total_tokens_title = len(bert_tokenizer.tokenize(title))\n",
    "    lenght_meta_description = len(bert_tokenizer.tokenize(meta_description))\n",
    "    lenght_keywords = len(bert_tokenizer.tokenize(keywords))\n",
    "    \n",
    "    title_lenght.append(total_tokens_title)\n",
    "    meta_description_lenght.append(lenght_meta_description)\n",
    "    keywords_lenght.append(lenght_keywords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title tokens analysis analysis:\n",
      "max words = 55\n",
      "min words = 1\n",
      "avg words = 10.085411083402333\n",
      "std words = 4.971531406496229\n"
     ]
    }
   ],
   "source": [
    "print('title tokens analysis analysis:')\n",
    "print(\"max words = \"+str(np.max(title_lenght)))\n",
    "print(\"min words = \"+str(np.min(title_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(title_lenght)))\n",
    "print(\"std words = \"+str(np.std(title_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-description tokens analysis analysis:\n",
      "max words = 3374\n",
      "min words = 1\n",
      "avg words = 27.660006761159586\n",
      "std words = 40.49967109947301\n"
     ]
    }
   ],
   "source": [
    "print('meta-description tokens analysis analysis:')\n",
    "print(\"max words = \"+str(np.max(meta_description_lenght)))\n",
    "print(\"min words = \"+str(np.min(meta_description_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(meta_description_lenght)))\n",
    "print(\"std words = \"+str(np.std(meta_description_lenght)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords tokens analysis analysis:\n",
      "max words = 107\n",
      "min words = 1\n",
      "avg words = 20.888303683852097\n",
      "std words = 5.0942223999569\n"
     ]
    }
   ],
   "source": [
    "print('keywords tokens analysis analysis:')\n",
    "print(\"max words = \"+str(np.max(keywords_lenght)))\n",
    "print(\"min words = \"+str(np.min(keywords_lenght)))\n",
    "print(\"avg words = \"+str(np.mean(keywords_lenght)))\n",
    "print(\"std words = \"+str(np.std(keywords_lenght)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
